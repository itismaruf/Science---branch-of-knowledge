import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

import plotly.express as px
import re
from AI_helper import get_chatgpt_response

def load_data(uploaded_file):
    import re

    filename = uploaded_file.name.lower()
    try:
        if filename.endswith((".xlsx", ".xls")):
            df = pd.read_excel(uploaded_file)
        elif filename.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
        else:
            raise ValueError("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CSV, XLSX –∏–ª–∏ XLS.")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
        raise

    conversion_log = []

    def looks_like_number(s):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞: –≤—ã–≥–ª—è–¥–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∫–∞–∫ —á–∏—Å–ª–æ"""
        s = s.strip().replace(",", ".")
        return bool(re.match(r"^-?\d+(\.\d+)?$", s))

    for col in df.columns:
        original_dtype = df[col].dtype
        if original_dtype == "object":
            # –£–¥–∞–ª–∏–º –ø—Ä–æ–±–µ–ª—ã –∏ –∑–∞–º–µ–Ω–∏–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏
            df[col] = df[col].astype(str).str.strip().str.replace(",", ".")

            # –ü—Ä–æ–≤–µ—Ä–∏–º, —Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ —á–∏—Å–ª–∞
            is_number_like = df[col].apply(looks_like_number)
            success_rate = is_number_like.mean()

            if success_rate > 0.9:
                try:
                    df[col] = pd.to_numeric(df[col], errors="raise")
                    conversion_log.append(f"{col}: object ‚Üí float (—É—Å–ø–µ—à–Ω–æ, {success_rate:.0%} —á–∏—Å–µ–ª)")
                except Exception:
                    df[col] = df[col].astype(str)
                    conversion_log.append(f"{col}: –æ—Å—Ç–∞–ª—Å—è –∫–∞–∫ —Ç–µ–∫—Å—Ç (–æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏)")
            else:
                conversion_log.append(f"{col}: –æ—Å—Ç–∞–ª—Å—è –∫–∞–∫ —Ç–µ–∫—Å—Ç ({success_rate:.0%} —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫)")
        else:
            conversion_log.append(f"{col}: {original_dtype} (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)")

    st.session_state["conversion_log"] = conversion_log

    base_info = {
        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫": df.shape[0],
        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤": df.shape[1],
        "–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è": int(df.isnull().sum().sum()),
        "–î—É–±–ª–∏–∫–∞—Ç—ã": int(df.duplicated().sum()),
        "–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏": len(df.select_dtypes(include=["number"]).columns),
        "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏": len(df.select_dtypes(include=["object"]).columns),
    }

    st.session_state["base_info"] = base_info
    st.subheader("üìä –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
    for key, value in base_info.items():
        st.markdown(f"- **{key}:** {value}")

    return df


def summarize_data(df):
    summary = f"""
### ‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ

- üî¢ **–†–∞–∑–º–µ—Ä:** {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤
- üìÑ **–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:**
{df.dtypes.to_string()}

- üß© **–ü—Ä–æ–ø—É—Å–∫–∏:**
{df.isnull().sum()[df.isnull().sum() > 0].to_string() if df.isnull().sum().sum() > 0 else '–ù–µ—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤'}

- üß™ **–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:**
{df.head(3).to_markdown()}
"""
    return summary


def summarize_columns_for_gpt(df):
    summary = []
    for col in df.columns:
        null_pct = round(df[col].isnull().mean() * 100, 1)
        examples = df[col].dropna().astype(str).unique()[:3]
        summary.append({
            "column": col,
            "type": str(df[col].dtype),
            "nulls": null_pct,
            "examples": list(examples)
        })
    return summary


def ask_gpt_smart_cleaning(summary):
    prompt = (
        "–ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —É–∫–∞–∂–∏, –∫–∞–∫–∏–µ —Å—Ç–æ–ª–±—Ü—ã –Ω—É–∂–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∏ —á–µ–º "
        "(mean, median –∏–ª–∏ mode), –∞ –∫–∞–∫–∏–µ –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å. –§–æ—Ä–º–∞—Ç:\n\n"
        "- –ó–∞–ø–æ–ª–Ω–∏—Ç—å: age: mean, city: mode\n"
        "- –ù–µ —Ç—Ä–æ–≥–∞—Ç—å: country, code\n\n"
        "–¢–æ–ª—å–∫–æ —Å–ø–∏—Å–æ–∫, –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤.\n\n"
        f"{summary}"
    )
    return get_chatgpt_response(prompt)  # —Ç—É—Ç –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –º–æ–¥–µ–ª—å


def apply_gpt_cleaning(df, gpt_response):
    import re
    to_fill = {}
    do_not_touch = []

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π GPT –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
    fill_part = re.search(r"- –ó–∞–ø–æ–ª–Ω–∏—Ç—å:\s*(.*?)(?:\n|$)", gpt_response)
    if fill_part:
        for item in fill_part.group(1).split(','):
            parts = item.strip().split(':')
            if len(parts) == 2:
                col, method = parts[0].strip(), parts[1].strip()
                if col in df.columns:
                    to_fill[col] = method

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π GPT –¥–ª—è –æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    notouch_part = re.search(r"- –ù–µ —Ç—Ä–æ–≥–∞—Ç—å:\s*(.*)", gpt_response)
    if notouch_part:
        do_not_touch = [x.strip() for x in notouch_part.group(1).split(',') if x.strip() in df.columns]

    cleaning_log = []

    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –∫–æ–ª–æ–Ω–∫–∞–º –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –æ—á–∏—Å—Ç–∫—É
    for col in df.columns:
        if col in to_fill:
            method = to_fill[col]
            if df[col].isnull().sum() > 0:
                try:
                    if method == "mean":
                        df[col].fillna(df[col].mean(), inplace=True)
                        cleaning_log.append(f"{col}: –∑–∞–ø–æ–ª–Ω–µ–Ω–æ (mean)")
                    elif method == "median":
                        df[col].fillna(df[col].median(), inplace=True)
                        cleaning_log.append(f"{col}: –∑–∞–ø–æ–ª–Ω–µ–Ω–æ (median)")
                    elif method == "mode":
                        mode_val = df[col].mode()
                        if not mode_val.empty:
                            df[col].fillna(mode_val[0], inplace=True)
                            cleaning_log.append(f"{col}: –∑–∞–ø–æ–ª–Ω–µ–Ω–æ (mode)")
                        else:
                            cleaning_log.append(f"{col}: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–æ–ª–Ω–∏—Ç—å (–ø—É—Å—Ç–æ–π mode)")
                    else:
                        cleaning_log.append(f"{col}: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è ({method})")
                except Exception as e:
                    cleaning_log.append(f"{col}: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–∏ ‚Üí {str(e)}")
            else:
                cleaning_log.append(f"{col}: –ø—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ—Ç, –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ")
        elif col in do_not_touch:
            cleaning_log.append(f"{col}: –æ—Å—Ç–∞–≤–ª–µ–Ω –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
        else:
            # –ï—Å–ª–∏ –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∏ –≤ –Ω–µ–π –µ—Å—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏, –ø—Ä–∏–º–µ–Ω—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ
            if df[col].isnull().sum() > 0:
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—á–∏—â–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                result = default_cleaning(df, col)
                cleaning_log.append(f"{col}: —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ–ø—É—Å–∫–∏, –Ω–µ —É–∫–∞–∑–∞–Ω –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è—Ö -> {result}")
            else:
                cleaning_log.append(f"{col}: –±–µ–∑ –ø—Ä–æ–ø—É—Å–∫–æ–≤")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥ –æ—á–∏—Å—Ç–∫–∏ –≤ session_state
    st.session_state["cleaning_log"] = cleaning_log
    return cleaning_log


def default_cleaning(df, column):
    """
    –û—á–∏—â–∞–µ—Ç –∫–æ–ª–æ–Ω–∫—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é:
    - –ï—Å–ª–∏ —á–∏—Å–ª–æ–≤–∞—è ‚Äì –∑–∞–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∏ —Å—Ä–µ–¥–Ω–∏–º.
    - –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è ‚Äì –∑–∞–ø–æ–ª–Ω—è–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (mode).
    """
    import pandas as pd
    if pd.api.types.is_numeric_dtype(df[column]):
        df[column].fillna(df[column].mean(), inplace=True)
        return "–æ—á–∏—â–µ–Ω–æ (mean)"
    else:
        mode_val = df[column].mode()
        if not mode_val.empty:
            df[column].fillna(mode_val[0], inplace=True)
            return "–æ—á–∏—â–µ–Ω–æ (mode)"
        else:
            return "–æ—á–∏—â–µ–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ (–ø—É—Å—Ç–æ–π mode)"


# –û—Ç—á—ë—Ç –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏

def generate_data_cleaning_report(df_original, df_cleaned):
    report = []

    rows_before = df_original.shape[0]
    rows_after = df_cleaned.shape[0]
    dups_removed = df_original.duplicated().sum()
    rows_removed = rows_before - rows_after

    report.append(f"- üßæ –ò—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: **{rows_before}**, –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: **{rows_after}**")
    report.append(f"- ‚ùå –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: **{dups_removed}**")
    report.append(f"- üßπ –í—Å–µ–≥–æ —É–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫: **{rows_removed}** (–¥—É–±–ª–∏–∫–∞—Ç—ã + —Å—Ç—Ä–æ–∫–∏ —Å >50% NaN)")

    nan_percent = df_original.isnull().mean().round(2) * 100
    if nan_percent[nan_percent > 0].empty:
        report.append("- ‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–æ –æ—á–∏—Å—Ç–∫–∏ –Ω–µ –±—ã–ª–æ.")
    else:
        report.append("### üîç –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ –æ—á–∏—Å—Ç–∫–∏:")
        report.append(nan_percent[nan_percent > 0].to_markdown())

    report.append("### üì¶ –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:")
    report.append(df_cleaned.dtypes.to_frame("–¢–∏–ø").to_markdown())

    unique_vals = df_cleaned.nunique()
    report.append("### üß¨ –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º:")
    report.append(unique_vals.to_frame("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö").to_markdown())

    return "\n\n".join(report)


def show_data_issues(issues_dict):
    st.subheader("üõ† –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö:")
    for k, v in issues_dict.items():
        st.markdown(f"**{k}:**")
        st.dataframe(v)


def plot_data_visualizations(df, x, y=None, top_n=None, numeric_filters=None, chart_type="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"):
    try:
        if y and x == y:
            st.warning("–í—ã –≤—ã–±—Ä–∞–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –æ—Å–µ–π X –∏ Y. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ.")
            return None

        if numeric_filters:
            for col, (min_val, max_val) in numeric_filters.items():
                df = df[df[col].between(min_val, max_val)]

        if top_n:
            if not pd.api.types.is_numeric_dtype(df[x]):
                top_categories_x = df[x].value_counts().nlargest(top_n).index
                df = df[df[x].isin(top_categories_x)]
            if y and not pd.api.types.is_numeric_dtype(df[y]):
                top_categories_y = df[y].value_counts().nlargest(top_n).index
                df = df[df[y].isin(top_categories_y)]

        x_is_num = pd.api.types.is_numeric_dtype(df[x])
        y_is_num = pd.api.types.is_numeric_dtype(df[y]) if y else False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç–æ–ª–±–µ—Ü ID –∏–ª–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º
        if df[x].nunique() == len(df[x]):
            st.warning("–í—ã –≤—ã–±—Ä–∞–ª–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä, ID). –î–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª–∞.")
            return None

        # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä—É—á–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ ---
        if chart_type != "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏":
            st.info(f"–í—ã–±—Ä–∞–Ω–Ω—ã–π —Ç–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞: **{chart_type}**")
            if chart_type == "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞":
                if x_is_num:
                    return px.histogram(
                        df,
                        x=x,
                        nbins=30,
                        title=f'Histogram: {x}',
                        color_discrete_sequence=px.colors.qualitative.Vivid  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏
                    )
                else:
                    return px.histogram(
                        df,
                        x=x,
                        title=f'Histogram: {x}',
                        color=x,
                        color_discrete_sequence=px.colors.qualitative.Safe
                    )
            elif chart_type == "–ö—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞":
                counts = df[x].value_counts()
                if top_n:
                    counts = counts.nlargest(top_n)
                return px.pie(
                    values=counts.values,
                    names=counts.index,
                    title=f'Pie Chart: {x}',
                    color_discrete_sequence=px.colors.qualitative.Bold
                )
            elif chart_type == "–¢–æ—á–µ—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫" and y:
                if not x_is_num:
                    color_param = x
                elif not y_is_num:
                    color_param = y
                else:
                    color_param = None
                if color_param:
                    return px.scatter(
                        df,
                        x=x,
                        y=y,
                        title=f'Scatter: {x} vs {y}',
                        color=color_param,
                        color_discrete_sequence=px.colors.qualitative.Dark2
                    )
                else:
                    return px.scatter(
                        df,
                        x=x,
                        y=y,
                        title=f'Scatter: {x} vs {y}',
                        color_continuous_scale=px.colors.sequential.Inferno
                    )
            elif chart_type == "Boxplot" and y:
                if not x_is_num:
                    return px.box(
                        df,
                        x=x,
                        y=y,
                        title=f'Boxplot: {x} vs {y}',
                        color=x,
                        color_discrete_sequence=px.colors.qualitative.Pastel2
                    )
                else:
                    return px.box(
                        df,
                        x=x,
                        y=y,
                        title=f'Boxplot: {x} vs {y}'
                    )
            elif chart_type == "Bar-–≥—Ä–∞—Ñ–∏–∫" and y:
                if not x_is_num:
                    return px.bar(
                        df,
                        x=x,
                        y=y,
                        title=f'Bar: {x} vs {y}',
                        color=x,
                        color_discrete_sequence=px.colors.qualitative.Bold
                    )
                else:
                    return px.bar(
                        df,
                        x=x,
                        y=y,
                        title=f'Bar: {x} vs {y}'
                    )
            elif chart_type == "–õ–∞–π–Ω–ø–ª–æ—Ç" and x and y:
                return px.line(
                    df,
                    x=x,
                    y=y,
                    title=f'Line Plot: {x} vs {y}',
                    markers=True,
                    color_discrete_sequence=px.colors.qualitative.Vivid
                )
            else:
                st.warning("–î–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –≤—Ç–æ—Ä–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è Y.")
                return None

        # --- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º ---
        if y:
            if x_is_num and y_is_num:
                st.info(f"–ì—Ä–∞—Ñ–∏–∫: Scatter ‚Äî —á–∏—Å–ª–æ–≤–∞—è –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å `{x}` –∏ `{y}`")
                return px.scatter(
                    df, x=x, y=y,
                    title=f'Scatter: {x} vs {y}',
                    color_continuous_scale=px.colors.sequential.Inferno
                )
            elif y_is_num and not x_is_num:
                if df[x].nunique() <= 5:
                    st.info(f"–ì—Ä–∞—Ñ–∏–∫: Bar ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ `{y}` –ø–æ `{x}`")
                    agg_df = df.groupby(x)[y].mean().reset_index()
                    return px.bar(
                        agg_df,
                        x=x,
                        y=y,
                        title=f'Bar: {x} vs {y}',
                        color=x,
                        color_discrete_sequence=px.colors.qualitative.Safe
                    )
                else:
                    st.info(f"–ì—Ä–∞—Ñ–∏–∫: Boxplot ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ `{y}` –ø–æ `{x}`")
                    return px.box(
                        df,
                        x=x,
                        y=y,
                        title=f'Boxplot: {x} vs {y}',
                        color=x,
                        color_discrete_sequence=px.colors.qualitative.Pastel2
                    )
            elif not x_is_num and not y_is_num:
                st.info(f"–ì—Ä–∞—Ñ–∏–∫: Bar ‚Äî –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ `{x}` —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ `{y}`")
                return px.histogram(
                    df,
                    x=x,
                    color=y,
                    barmode="group",
                    title=f'Bar: {x} by {y}',
                    color_discrete_sequence=px.colors.qualitative.Bold
                )
            else:
                return px.bar(
                    df,
                    x=x,
                    y=y,
                    title=f'Bar: {x} vs {y}',
                    color_discrete_sequence=px.colors.qualitative.Safe
                )
        else:
            if x_is_num:
                st.info(f"–ì—Ä–∞—Ñ–∏–∫: Histogram ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π `{x}`")
                return px.histogram(
                    df,
                    x=x,
                    nbins=30,
                    title=f'Histogram: {x}',
                    color_discrete_sequence=px.colors.qualitative.Pastel
                )
            else:
                counts = df[x].value_counts()
                if top_n:
                    counts = counts.nlargest(top_n)
                st.info(f"–ì—Ä–∞—Ñ–∏–∫: Pie ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ `{x}`")
                return px.pie(
                    values=counts.values,
                    names=counts.index,
                    title=f'Pie Chart: {x}',
                    color_discrete_sequence=px.colors.qualitative.Bold
                )

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        return None




# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —Ç—â–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–∞–Ω–Ω—ã—Ö
def train_model(df, target_column, model_type):
    df = df.copy()
    st.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    if target_column not in df.columns:
        st.error("‚ùå –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö.")
        return None, None, None, None, None

    if df[target_column].nunique() < 2:
        st.error(
            "‚ùå –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –∫–∞–∫ –º–∏–Ω–∏–º—É–º –¥–≤–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è. "
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π —Å—Ç–æ–ª–±–µ—Ü."
        )
        return None, None, None, None, None

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    X = df.drop(columns=[target_column])
    y = df[target_column]

    # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ —è–≤–Ω–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ID)
    for col in X.columns:
        if X[col].nunique() == len(X[col]):
            st.warning(f"‚ö†Ô∏è –°—Ç–æ–ª–±–µ—Ü '{col}' –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏ –±—É–¥–µ—Ç –∏—Å–∫–ª—é—á—ë–Ω –∏–∑ –æ–±—É—á–µ–Ω–∏—è.")
            X = X.drop(columns=[col])

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    for col in X.select_dtypes(include='object').columns:
        X[col] = LabelEncoder().fit_transform(X[col].astype(str))

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    if X.isnull().any().any() or y.isnull().any():
        st.error(
            "‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö. "
            "–ú–æ–¥–µ–ª—å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—É—á–µ–Ω–∞, –ø–æ–∫–∞ –æ–Ω–∏ –Ω–µ –±—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. "
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å —Ñ—É–Ω–∫—Ü–∏–µ–π —É–º–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –∏–ª–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞–Ω–Ω—ã—Ö."
        )
        return None, None, None, None, None

    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    if y.dtype == "object":
        y = LabelEncoder().fit_transform(y.astype(str))

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ (80/20)
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞
    if model_type == "Decision Tree":
        model = DecisionTreeClassifier(random_state=42)
    elif model_type == "Logistic Regression":
        model = LogisticRegression(max_iter=200, random_state=42)
    elif model_type == "Neural Network":
        model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)
    elif model_type == "Random Forest":
        model = RandomForestClassifier(random_state=42)
    elif model_type == "Support Vector Machine":
        model = SVC(probability=True, random_state=42)
    elif model_type == "K Nearest Neighbors":
        model = KNeighborsClassifier(n_neighbors=5)
    elif model_type == "Gradient Boosting":
        model = GradientBoostingClassifier(random_state=42)
    else:
        st.error("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏.")
        return None, None, None, None, None

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    metrics = classification_report(y_test, y_pred, output_dict=True)
    st.success("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

    return metrics, model, X_test, y_test, y_pred

def plot_predictions(y_test, y_pred):
    st.subheader("üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π**")
        fig_true, ax_true = plt.subplots()
        sns.histplot(y_test, kde=False, color="green", ax=ax_true, bins=10)
        ax_true.set_title("–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
        ax_true.set_xlabel("–ö–ª–∞—Å—Å—ã")
        ax_true.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
        st.pyplot(fig_true)

    with col2:
        st.markdown("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π**")
        fig_pred, ax_pred = plt.subplots()
        sns.histplot(y_pred, kde=False, color="blue", ax=ax_pred, bins=10)
        ax_pred.set_title("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
        ax_pred.set_xlabel("–ö–ª–∞—Å—Å—ã")
        ax_pred.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
        st.pyplot(fig_pred)

    # –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫
    st.markdown("**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:**")
    accuracy = (y_test == y_pred).mean() * 100
    st.success(f"–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {accuracy:.2f}%")
